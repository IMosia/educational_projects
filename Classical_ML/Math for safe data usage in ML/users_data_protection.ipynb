{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Protection of personal data of clients\n",
    "It is necessary to protect the data of clients of the insurance company \"Want a Flood\". Namely, we need to develop a method of data transformation in a way that it would be difficult to recover personal information from it, and justify the correctness of its work.\n",
    "\n",
    "At the same time, it is necessary to protect the data in such a way that the quality of machine learning models does not deteriorate during the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meeting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>salary</th>\n",
       "      <th>relatives</th>\n",
       "      <th>insurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.499000</td>\n",
       "      <td>30.952800</td>\n",
       "      <td>39916.360000</td>\n",
       "      <td>1.194200</td>\n",
       "      <td>0.148000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500049</td>\n",
       "      <td>8.440807</td>\n",
       "      <td>9900.083569</td>\n",
       "      <td>1.091387</td>\n",
       "      <td>0.463183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>5300.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>33300.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>40200.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>46600.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>79000.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            gender          age        salary    relatives    insurance\n",
       "count  5000.000000  5000.000000   5000.000000  5000.000000  5000.000000\n",
       "mean      0.499000    30.952800  39916.360000     1.194200     0.148000\n",
       "std       0.500049     8.440807   9900.083569     1.091387     0.463183\n",
       "min       0.000000    18.000000   5300.000000     0.000000     0.000000\n",
       "25%       0.000000    24.000000  33300.000000     0.000000     0.000000\n",
       "50%       0.000000    30.000000  40200.000000     1.000000     0.000000\n",
       "75%       1.000000    37.000000  46600.000000     2.000000     0.000000\n",
       "max       1.000000    65.000000  79000.000000     6.000000     5.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "gender       0\n",
       "age          0\n",
       "salary       0\n",
       "relatives    0\n",
       "insurance    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>salary</th>\n",
       "      <th>relatives</th>\n",
       "      <th>insurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4847.000000</td>\n",
       "      <td>4847.000000</td>\n",
       "      <td>4847.000000</td>\n",
       "      <td>4847.000000</td>\n",
       "      <td>4847.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.498453</td>\n",
       "      <td>31.023932</td>\n",
       "      <td>39895.811842</td>\n",
       "      <td>1.203425</td>\n",
       "      <td>0.152259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500049</td>\n",
       "      <td>8.487995</td>\n",
       "      <td>9972.953985</td>\n",
       "      <td>1.098664</td>\n",
       "      <td>0.468934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>5300.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>33200.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>40200.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>46600.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>79000.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            gender          age        salary    relatives    insurance\n",
       "count  4847.000000  4847.000000   4847.000000  4847.000000  4847.000000\n",
       "mean      0.498453    31.023932  39895.811842     1.203425     0.152259\n",
       "std       0.500049     8.487995   9972.953985     1.098664     0.468934\n",
       "min       0.000000    18.000000   5300.000000     0.000000     0.000000\n",
       "25%       0.000000    24.000000  33200.000000     0.000000     0.000000\n",
       "50%       0.000000    30.000000  40200.000000     1.000000     0.000000\n",
       "75%       1.000000    37.000000  46600.000000     2.000000     0.000000\n",
       "max       1.000000    65.000000  79000.000000     6.000000     5.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4847 entries, 0 to 4999\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   gender     4847 non-null   int64  \n",
      " 1   age        4847 non-null   float64\n",
      " 2   salary     4847 non-null   float64\n",
      " 3   relatives  4847 non-null   int64  \n",
      " 4   insurance  4847 non-null   int64  \n",
      "dtypes: float64(2), int64(3)\n",
      "memory usage: 227.2 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    data = pd.read_csv('/datasets/insurance.csv')\n",
    "except:\n",
    "    data = pd.read_csv('C:/Users/Ivan/datasetsYP/insurance.csv')\n",
    "    \n",
    "data.columns = ['gender', 'age', 'salary', 'relatives', 'insurance']\n",
    "display(data.describe())\n",
    "display(data.isnull().sum())\n",
    "print(data.duplicated().sum())\n",
    "data = data.drop_duplicates(keep='first')\n",
    "display(data.describe())\n",
    "display(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions**: Data downloaded and examined. No obvious outliers were found. However, there were 153 complete duplicates in the data, given that wages have many different values (as opposed to gender, age, number of family members, and insurance benefits), duplicates should not occur, so they were removed. Apparently, duplicates are missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Multiplication\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denotations:\n",
    "\n",
    "- $X$ - feature matrix (zero column consists of units)\n",
    "\n",
    "- $y$ - vector of target attribute\n",
    "\n",
    "- $P$ - matrix by which the signs are multiplied\n",
    "\n",
    "- $w$ - vector of linear regression weights (zero element is equal to the shift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions:\n",
    "\n",
    "$$\n",
    "a = Xw\n",
    "$$\n",
    "\n",
    "Learning formula:\n",
    "\n",
    "$$\n",
    "w = (X^T X)^{-1} X^T y\n",
    "$$\n",
    "\n",
    "New parameters:\n",
    "$$\n",
    "X_n = X P\n",
    "$$\n",
    "\n",
    "Let's focus on the new parameters:\n",
    "\n",
    "$$\n",
    "w_n = (X_n^T X_n)^{-1} X_n^T y = ((XP)^T (XP))^{-1} (XP)^T y\n",
    "$$\n",
    "We can solve the transpose ( (XP)^T = P^T X^T ):\n",
    "\n",
    "$$\n",
    "w_n = (P^T X^T X P)^{-1} P^T X^T y\n",
    "$$\n",
    "\n",
    "Now let's solve the -1 degree:\n",
    "\n",
    "$$\n",
    "(A @ B @ C)^{-1} = C^{-1} (A B)^{-1} = C^{-1} B^{-1} A^{-1}\n",
    "A = P^T, B = (X^T X), C = P  \n",
    "$$\n",
    "We can, since X^T X gives a guaranteed square matrix (reversible)\n",
    "\n",
    "$$\n",
    "w_n = P^{-1} (X^T X)^{-1} P^T^{-1} P^T X^T y \n",
    "$$\n",
    "\n",
    "$$\n",
    "w_n = P^{-1} (X^T X)^{-1} X^T y\n",
    "$$\n",
    "Since:\n",
    "$$\n",
    "w = (X^T X)^{-1} X^T y\n",
    "$$\n",
    "We can simply substitute w:\n",
    "$$\n",
    "w_n = P^{-1} w\n",
    "$$\n",
    "Finally, let's substitute in the prediction:\n",
    "$$\n",
    "a_n = X_n w_n = X P P^{-1} w = X w = a\n",
    "$$\n",
    "The old and new predictions are equal!\n",
    "**Proved**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion Algorithm\n",
    "**Algorithm**\n",
    "\n",
    "Based on the algorithm showed above, we will multiply the feature matrix by an additional matrix (P) with constant values. The values for the matrix will be randomly generated and will be used for both training and test samples.\n",
    "\n",
    "Since we want to keep the number of features and the number of users constant, the matrix P should be quadratic with dimension n - the number of features. It should also be linearly independent so that the features do not degenerate, and the related property is non-degeneracy so that we can perform reconstruction of the original features.\n",
    "\n",
    "Thus, it is necessary to:\n",
    "Obtain a random unexpanded quadratic matrix (P) with dimension n (number of features)  \n",
    "Check it for reversibility (respectively, non-convexity)  \n",
    "Multiply the original feature matrix X by the matrix P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rationale**.\n",
    "Quadraticity and matrix size:  \n",
    "There is a matrix X of size mxn, where m is the number of users, n is the number of features  \n",
    "We need to obtain a new matrix X' of the same dimension as follows:  \n",
    "X' = X P  \n",
    "hence the dimension of the matrix P must be n by n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformation of attributes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matix is not degenerate - everything is fine!\n",
      "\n",
      "The Matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.37454012, 0.95071431, 0.73199394, 0.59865848],\n",
       "       [0.15601864, 0.15599452, 0.05808361, 0.86617615],\n",
       "       [0.60111501, 0.70807258, 0.02058449, 0.96990985],\n",
       "       [0.83244264, 0.21233911, 0.18182497, 0.18340451]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N_FEATURES = data.shape[1] - 1\n",
    "our_random_state = RandomState(42)\n",
    "\n",
    "def get_rand_matrix(N_FEATURES):\n",
    "    det = 0\n",
    "    while det == 0:\n",
    "        matrix = our_random_state.rand(N_FEATURES, N_FEATURES)\n",
    "        det = np.linalg.det(matrix)\n",
    "    return matrix\n",
    "\n",
    "P_matrix = get_rand_matrix(N_FEATURES)\n",
    "\n",
    "# Check for reversibility (determinant is not equal to 0)\n",
    "if np.linalg.det(P_matrix) != 0:\n",
    "    print('Matix is not degenerate - everything is fine!')\n",
    "else:\n",
    "    print('It was not supposed to be like this...')\n",
    "\n",
    "#  Function for parameter conversion using a pre-generated random matrix\n",
    "def get_transformed_features(old_features):\n",
    "    return old_features @ P_matrix\n",
    "\n",
    "print('\\nThe Matrix:')\n",
    "display(P_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions**: conditions for conversion are formulated, and the basis for feature conversion is prepared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm validation\n",
    "Let's perform calculations and predictions for two data sets: unchanged and transformed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model starting parametrs r2 = 0.4434633083161058\n",
      "\n",
      "For model modified parametrs r2 = 0.4434633083154019\n",
      "\n",
      "Difference in prediction quality = 7.038813976123492e-13\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                    data[data.columns[:-1]].values, data[data.columns[-1]].values, \n",
    "                                    test_size=0.25, random_state=42)\n",
    "\n",
    "# Let's get new transformed parameters\n",
    "X_train_transformed = get_transformed_features(X_train)\n",
    "X_test_transformed = get_transformed_features(X_test)\n",
    "\n",
    "# Let's create a function that will train the model and determine its quality\n",
    "def linear_regression_checker(name, X_train, X_test, y_train, y_test):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    r2 = model.score(X_test, y_test)\n",
    "    print(f'For model {name} r2 = {r2}\\n')\n",
    "    return r2\n",
    "\n",
    "# Let's use it for both cases\n",
    "r2_not_transformed = linear_regression_checker('starting parametrs', X_train, X_test, y_train, y_test)\n",
    "r2_transformed = linear_regression_checker('modified parametrs', X_train_transformed,\n",
    "                          X_test_transformed, y_train, y_test)\n",
    "print(f'Difference in prediction quality = {r2_not_transformed - r2_transformed}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus the accuracy of predictions for transformed and untransformed parameters can be considered unchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "1) The data were downloaded and examined, duplicates found were removed.\n",
    "2) It is shown that multiplication of the feature matrix by a random reversible matrix does not affect the predictions.\n",
    "3) A transformation algorithm (multiplication of the feature matrix by a quadratic nondegenerate matrix filled with random numbers with dimensionality corresponding to the number of features) is designed and implemented.\n",
    "4) Verification showed that the models trained and tested on transformed and untransformed features have the same accuracy."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 603,
    "start_time": "2023-09-05T14:21:24.403Z"
   },
   {
    "duration": 3,
    "start_time": "2023-09-05T14:21:42.889Z"
   },
   {
    "duration": 138,
    "start_time": "2023-09-05T14:22:07.935Z"
   },
   {
    "duration": 77,
    "start_time": "2023-09-05T14:22:53.085Z"
   },
   {
    "duration": 71,
    "start_time": "2023-09-05T14:23:09.387Z"
   },
   {
    "duration": 61,
    "start_time": "2023-09-05T14:23:20.333Z"
   },
   {
    "duration": 66,
    "start_time": "2023-09-05T14:23:52.042Z"
   },
   {
    "duration": 66,
    "start_time": "2023-09-05T14:23:58.634Z"
   },
   {
    "duration": 81,
    "start_time": "2023-09-05T14:24:11.145Z"
   },
   {
    "duration": 84,
    "start_time": "2023-09-05T14:25:58.665Z"
   },
   {
    "duration": 93,
    "start_time": "2023-09-05T14:26:35.084Z"
   },
   {
    "duration": 79,
    "start_time": "2023-09-05T14:26:51.755Z"
   },
   {
    "duration": 128,
    "start_time": "2023-09-05T14:27:05.285Z"
   },
   {
    "duration": 1325,
    "start_time": "2023-09-05T14:50:41.526Z"
   },
   {
    "duration": 108,
    "start_time": "2023-09-05T14:50:42.855Z"
   },
   {
    "duration": 100,
    "start_time": "2023-09-05T15:42:52.079Z"
   },
   {
    "duration": 13,
    "start_time": "2023-09-05T15:44:51.140Z"
   },
   {
    "duration": 9,
    "start_time": "2023-09-05T15:50:21.268Z"
   },
   {
    "duration": 1174,
    "start_time": "2023-09-05T15:50:37.566Z"
   },
   {
    "duration": 90,
    "start_time": "2023-09-05T15:50:38.742Z"
   },
   {
    "duration": 5,
    "start_time": "2023-09-05T15:50:38.834Z"
   },
   {
    "duration": 5,
    "start_time": "2023-09-05T15:50:38.841Z"
   },
   {
    "duration": 13,
    "start_time": "2023-09-05T15:50:56.817Z"
   },
   {
    "duration": 7,
    "start_time": "2023-09-05T15:51:00.726Z"
   },
   {
    "duration": 8,
    "start_time": "2023-09-05T15:51:02.565Z"
   },
   {
    "duration": 7,
    "start_time": "2023-09-05T15:51:04.745Z"
   },
   {
    "duration": 111,
    "start_time": "2023-09-05T15:53:26.870Z"
   },
   {
    "duration": 1126,
    "start_time": "2023-09-05T15:53:35.845Z"
   },
   {
    "duration": 88,
    "start_time": "2023-09-05T15:53:36.973Z"
   },
   {
    "duration": 7,
    "start_time": "2023-09-05T15:53:37.064Z"
   },
   {
    "duration": 7,
    "start_time": "2023-09-05T15:53:37.073Z"
   },
   {
    "duration": 7,
    "start_time": "2023-09-05T15:53:41.465Z"
   },
   {
    "duration": 7,
    "start_time": "2023-09-05T15:53:44.340Z"
   },
   {
    "duration": 7,
    "start_time": "2023-09-05T15:53:45.877Z"
   },
   {
    "duration": 13,
    "start_time": "2023-09-05T15:53:47.608Z"
   },
   {
    "duration": 10,
    "start_time": "2023-09-05T15:54:02.709Z"
   },
   {
    "duration": 119,
    "start_time": "2023-09-05T16:00:01.658Z"
   },
   {
    "duration": 113,
    "start_time": "2023-09-05T16:00:16.538Z"
   },
   {
    "duration": 12,
    "start_time": "2023-09-05T16:00:36.787Z"
   },
   {
    "duration": 1121,
    "start_time": "2023-09-05T16:00:41.557Z"
   },
   {
    "duration": 91,
    "start_time": "2023-09-05T16:00:42.681Z"
   },
   {
    "duration": 7,
    "start_time": "2023-09-05T16:00:42.774Z"
   },
   {
    "duration": 38,
    "start_time": "2023-09-05T16:00:42.783Z"
   },
   {
    "duration": 12,
    "start_time": "2023-09-05T16:02:18.324Z"
   },
   {
    "duration": 125,
    "start_time": "2023-09-05T16:02:47.556Z"
   },
   {
    "duration": 13,
    "start_time": "2023-09-05T16:03:48.519Z"
   },
   {
    "duration": 1197,
    "start_time": "2023-09-05T16:05:28.524Z"
   },
   {
    "duration": 108,
    "start_time": "2023-09-05T16:05:29.723Z"
   },
   {
    "duration": 9,
    "start_time": "2023-09-05T16:05:29.833Z"
   },
   {
    "duration": 26,
    "start_time": "2023-09-05T16:05:29.843Z"
   },
   {
    "duration": 2511,
    "start_time": "2023-09-05T18:27:05.390Z"
   },
   {
    "duration": 134,
    "start_time": "2023-09-05T18:27:07.903Z"
   },
   {
    "duration": 7,
    "start_time": "2023-09-05T18:27:08.039Z"
   },
   {
    "duration": 43,
    "start_time": "2023-09-05T18:27:08.049Z"
   },
   {
    "duration": 1290,
    "start_time": "2023-09-06T06:41:19.599Z"
   },
   {
    "duration": 208,
    "start_time": "2023-09-06T06:41:20.891Z"
   },
   {
    "duration": 10,
    "start_time": "2023-09-06T06:41:21.102Z"
   },
   {
    "duration": 29,
    "start_time": "2023-09-06T06:41:21.116Z"
   },
   {
    "duration": 1408,
    "start_time": "2023-09-06T06:56:36.185Z"
   },
   {
    "duration": 128,
    "start_time": "2023-09-06T06:56:37.595Z"
   },
   {
    "duration": 10,
    "start_time": "2023-09-06T06:56:37.725Z"
   },
   {
    "duration": 24,
    "start_time": "2023-09-06T06:56:37.746Z"
   },
   {
    "duration": 9,
    "start_time": "2023-09-06T07:00:20.553Z"
   },
   {
    "duration": 8,
    "start_time": "2023-09-06T07:00:30.633Z"
   },
   {
    "duration": 8,
    "start_time": "2023-09-06T07:01:00.887Z"
   },
   {
    "duration": 11,
    "start_time": "2023-09-06T07:01:15.633Z"
   },
   {
    "duration": 13,
    "start_time": "2023-09-06T07:01:50.574Z"
   },
   {
    "duration": 16046,
    "start_time": "2023-09-06T07:02:58.392Z"
   },
   {
    "duration": 1487,
    "start_time": "2023-09-06T07:07:13.924Z"
   },
   {
    "duration": 168,
    "start_time": "2023-09-06T07:07:15.414Z"
   },
   {
    "duration": 18,
    "start_time": "2023-09-06T07:07:15.590Z"
   },
   {
    "duration": 18929,
    "start_time": "2023-09-06T07:07:15.616Z"
   },
   {
    "duration": 27,
    "start_time": "2023-09-06T07:07:34.553Z"
   },
   {
    "duration": 1409,
    "start_time": "2023-09-06T08:30:18.000Z"
   },
   {
    "duration": 149,
    "start_time": "2023-09-06T08:30:19.415Z"
   },
   {
    "duration": 14,
    "start_time": "2023-09-06T08:30:19.573Z"
   },
   {
    "duration": 16826,
    "start_time": "2023-09-06T08:30:19.590Z"
   },
   {
    "duration": 34,
    "start_time": "2023-09-06T08:30:36.418Z"
   },
   {
    "duration": 1209,
    "start_time": "2023-09-06T08:35:06.777Z"
   },
   {
    "duration": 107,
    "start_time": "2023-09-06T08:35:07.989Z"
   },
   {
    "duration": 9,
    "start_time": "2023-09-06T08:35:08.098Z"
   },
   {
    "duration": 14159,
    "start_time": "2023-09-06T08:35:08.109Z"
   },
   {
    "duration": 12,
    "start_time": "2023-09-06T08:35:22.270Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "109px",
    "width": "314px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
